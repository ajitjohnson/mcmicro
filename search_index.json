[
["index.html", "Image Processing Pipeline Quick Start", " Image Processing Pipeline Laboratory of Systems Pharmacology Last Updated: 2019-07-23 Quick Start Stitch and register your images with ASHLAR Segment your images using U-Net Quantify segmentation masks using headless HistoCAT Assign cell type identities The instructions are under development as the LSP image processing pipeline matures. If you have a module that you would like to see included, please view the vignette on how to contribute to this guide. "],
["howto.html", "How To Contribute", " How To Contribute If you already have a fork from previous contributions, you may want to synchronize it with the labsyspharm repository. If your fork currently doesn’t have any new changes from the live version, the easiest thing to do is delete the fork and re-fork. Go to your personal fork, click on the Settings tab, scroll all the way to the bottom and press “Delete Repository”. Proceed to Step 2 to refork. If your fork does deviate from the live version, you might want to rebase it. Follow the Git rebase guide, or get in touch with Artem or Jeremy for help. Go to https://github.com/labsyspharm/mcmicro and press “Fork” in the top right corner. In the Fork dialogue, select your personal GitHub account to fork the project to. Edit the .md files to add content. For formatting reference, see https://bookdown.org/yihui/bookdown/markdown-syntax.html If creating new .md files, add their filenames to _bookdown.yml. When finished, navigate to your personal fork (usually https://github.com/YourUsername/mcmicro) and press “New pull request”. Review the changes and press “Create pull request” when ready. Other teammates will review and comment on your changes. Once approved, the changes will appear on the live website. "],
["ashlar.html", "1 Image Stitching and Registration", " 1 Image Stitching and Registration Additional content here "],
["preprocess.html", "2 Image Preprocessing", " 2 Image Preprocessing Images can be preprocessed by inferring nuclei contours via a pretrained UNet model. The model is trained on 3 classes : background, nuclei contours and nuclei centers. The resulting probability maps can then be loaded into any modular segmentation pipeline that may use (but not limited to) a marker controlled watershed algorithm. The only input file is: an .ome.tif or .tif (preferably flat field corrected, minimal saturated pixels, and in focus. The model is trained on images acquired at 20x with binning 2x2 or a pixel size of 0.65 microns/px. If your settings differ, you can upsample/downsample to some extent. How to install: 1. Copy the python script, UNet model, and ImageScience toolbox to your computer. Clone from https://github.com/HMS-IDAC/UNet4Sage.git 2. Pip install tensorflow (or tensorflow_gpu with CUDA drivers and CuDNN libraries), matplotlib, scikit-image, Pillow, tifffile, Image, scipy How to run: 3. Open the python script batchUNet2DtCycif.py in an editor. 4. Make the following changes to the code to reflect the locations of your data and supporting files: -line 10 update the path to the ImageScience toolbox folder sys.path.insert(0, 'path//to//UNet code//ImageScience') -line 509 update the path to the model modelPath = 'modelPath = 'path//to//UNet code//TFModel - 3class 16 kernels 5ks 2 layers' -line 515 update the path to the top level experiment folder of the data imagePath = 'path//to//parent//folder//of//data' your files should be stored in a subfolder called registration -line 516 : if you have multiple samples and they have a similar prefix, add the prefix/suffix here: sampleList = glob.glob(imagePath + '//105*') -line 520 : if your files have a different extension from tif, you can change the extension here: fileList = glob.glob(iSample + '//registration//*.tif') some helpful tips: 5. -line 517 - specify the channel to infer nuclei contours and centers. If you want to run UNet on the 1st channel (sometimes DAPI/Hoechst), put 0. -line 518 - if you acquired your images at a higher magnification (ie. 40x), you may want to downsample your image so that it is more similar to the trained model (ie. 20x binning 2x2, pixel size 0.65 microns). in your terminal, activate your virtual environment and run this python script: python batchUNet2DtCycif.py If using tensorflow-gpu, your GPU card should be found. If not, prepare to hear your CPU fan fly! The probabilty map for the contours will be saved as a 3D tif file (concatenated with the original channel) and saved in a subfolder called `probmaps. The channel index you specified for inference is saved in the filename. References: S Saka, Y Wang, J Kishi, A Zhu, Y Zeng, W Xie, K Kirli, C Yapp, M Cicconet, BJ Beliveau, SW Lapan, S Yin, M Lin, E Boyde, PS Kaeser, G Pihan, GM Church, P Yin, Highly multiplexed in situ protein imaging with signal amplification by Immuno-SABER, Nat Biotechnology (accepted) "],
["segment.html", "3 Image Segmentation", " 3 Image Segmentation S3segmenter is a Matlab-based set of functions that generates single cell (nuclei and cytoplasm) label masks. Inputs are: an .ome.tif (preferably flat field corrected) a 3-class probability maps derived from a deep learning model such as UNet. Classes include background, nuclei contours, and nuclei foreground. The centers of each nuclei are obtained by finding local maxima from the nuclei foreground. These are used for marker-controlled watershed constrained by the nuclei contours. To segment cytoplasm, the nuclei are in turn used for a marker-controlled watershed segmentation constrained by a cytoplasmic marker such as B-catenin. The channel number of this marker must be specified. A 3-pixel annulus around each nucleus will also be used to segment cytoplasm. How to run: In Matlab, set path to the folder of the cloned repo. Type: O2batchS3segmenterWrapperR('/path/to/files/') Use the following name-value pairs arguments to customize the code to your experiment: ip.addParamValue(&#39;HPC&#39;,&#39;false&#39;,@(x)(ismember(x,{&#39;true&#39;,&#39;false&#39;}))); % if using a cluster, this specifies which file index to work on ip.addParamValue(&#39;fileNum&#39;,1,@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % select any number of channels for cytoplasm ip.addParamValue(&#39;CytoMaskChan&#39;,[2],@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % select any number of channels for tissue mask ip.addParamValue(&#39;TissueMaskChan&#39;,[3],@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % constrict the tissue mask to eliminate high autofluorescent regions ip.addParamValue(&#39;RefineTissueMask&#39;,[0],@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % set to true if sample is TMA cores ip.addParamValue(&#39;mask&#39;,&#39;tissue&#39;,@(x)(ismember(x,{&#39;TMA&#39;,&#39;tissue&#39;,&#39;none&#39;}))); % interactiveCrop - a GUI-based crop selector, % &#39;autoCrop&#39; - takes the middle third region, % &#39;dearray&#39;, set to true if using TMA cores, % &#39;noCrop&#39;, no cropping ip.addParamValue(&#39;crop&#39;,&#39;noCrop&#39;,@(x)(ismember(x,{&#39;interactiveCrop&#39;,&#39;autoCrop&#39;,&#39;dearray&#39;,&#39;noCrop&#39;}))); ip.addParamValue(&#39;cytoMethod&#39;,&#39;distanceTransform&#39;,@(x)(ismember(x,{&#39;RF&#39;,&#39;distanceTransform&#39;,&#39;bwdistanceTransform&#39;,&#39;ring&#39;}))); % feature to threshold nuclei. % &#39;IntPM&#39; - intensity of probability map, % &#39;Int&#39; - intensity of DAPI channel, % &#39;LoG&#39;, intensity of LoG filter response, % &#39;none&#39;, accept all nuclei ip.addParamValue(&#39;nucleiFilter&#39;,&#39;IntPM&#39;,@(x)(ismember(x,{&#39;LoG&#39;,&#39;Int&#39;,&#39;IntPM&#39;,&#39;none&#39;}))); % extracts intensity features from mask ip.addParamValue(&#39;measureFeatures&#39;,&#39;false&#39;,@(x)(ismember(x,{&#39;true&#39;,&#39;false&#39;}))); ip.addParamValue(&#39;nucleiRegion&#39;,&#39;watershedContourInt&#39;,@(x)(ismember(x,{&#39;watershedContourDist&#39;,&#39;watershedContourInt&#39;,&#39;watershedBWDist&#39;,&#39;dilation&#39;}))); ip.addParamValue(&#39;resizeFactor&#39;,1,@(x)(numel(x) == 1 &amp; all(x &gt; 0 ))); % specify range of nuclei diameters in pixels ie [3 30]. ip.addParamValue(&#39;logSigma&#39;,[2.5],@(x)(numel(x) &gt;0 &amp; all(x &gt; 0 ))); % channels for measuring features. If 0, assume all channels. ip.addParamValue(&#39;chanRange&#39;,[0],@(x)(numel(x) &gt;0 &amp; all(x &gt; 0 ))); ip.addParamValue(&#39;upSample&#39;,2,@(x)(numel(x) == 1 &amp; all(x &gt; 0 ))); ip.addParamValue(&#39;Docker&#39;,&#39;false&#39;,@(x)(ismember(x,{&#39;true&#39;,&#39;false&#39;}))); ip.addParamValue(&#39;dockerParams&#39;,0,@(x)(numel(x)==1)); Segmentation label masks for nuclei, cytoplasm, and cell will be saved to a subfolder under each parent image folder as a .tif file. Also saved are a 2-channel tif file with the DAPI and nuclei outlines for quality control. References: S Saka, Y Wang, J Kishi, A Zhu, Y Zeng, W Xie, K Kirli, C Yapp, M Cicconet, BJ Beliveau, SW Lapan, S Yin, M Lin, E Boyde, PS Kaeser, G Pihan, GM Church, P Yin, Highly multiplexed in situ protein imaging with signal amplification by Immuno-SABER, Nat Biotechnology (accepted) "],
["histocat.html", "4 Quantification of segmentation masks using headless HistoCAT", " 4 Quantification of segmentation masks using headless HistoCAT Additional content here "],
["celltype.html", "5 Assignment of cell type/state identity", " 5 Assignment of cell type/state identity Once segmentation masks have been quantified, the resulting cell-by-marker matrices can be used to assign cell type/state identity to individual cells. Methods to do this generally fall into two categories. The first set of methods typically begin by clustering cells into distinct subpopulations. The clusters are then inspected for the expression of specific markers, and cell type/state labeles are assigned to all cells belonging to that cluster. More sophisticated methods allow for “soft” assignment of cells to multiple clusters at once, which produces probabilistic assignment of cell types/states. The second class of methods forgo clustering entirely and work directly with the cell-by-marker matrix on a per-row (i.e., per-cell) basis. In the presence of labels, cell type assignment becomes a standard supervised learning task, where a model can be learned from labeled cells and applied to classify unlabeled ones. In the absence of labels, cell type assignment requires some prior knowledge about which markers map to which cell types/states. Given this mapping, assignment of cell identity can be done directly from marker expression. Expected input: An n-by-p matrix of n cells (rows) with quantified expression across p markers (columns) [optional] An n-by-1 vector of labels obtained through, e.g., manual curation [optional] A k-by-2 matrix that maps k channels to the corresponding cell type Expected output: An n-by-(p+1) matrix that encapsulates the original data with a new additional column denoting cell type assignments made by the method. In the case of probabilistic assigment, the method may output additional columns specifying per-class probabilities. Clustering-based methods Traditional supervised learning Method employing prior knowledge naivestates - Inference of cell states using a Naive Bayes framework. The method models each channel / marker as a mixture of two Gaussians. The resulting posterior probabilities of marker expression are combined with a pre-defined marker -&gt; cell type/state mapping to arrive at probabilistic assignment of cells to classes. "]
]
